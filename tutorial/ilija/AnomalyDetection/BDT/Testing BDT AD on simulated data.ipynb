{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Boosted Decision Tree based Anomaly Detection on simulated data\n",
    "\n",
    "#### This code generates large dataframe containing multiple timeseries, randomly adds changes in both mean and variance (anomalies), tries to train a BDT to distinguish measurements belonging to the timebin under investigation from measurements in a reference time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from pandas.tseries.offsets import *\n",
    "\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameters to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(17)\n",
    "\n",
    "n_series = 6\n",
    "start_date = '2017-08-01 00:00:00'\n",
    "end_date = '2017-08-07 23:59:59'\n",
    "\n",
    "# regular behaviour\n",
    "max_noise_amplitude = 0.05 # all the timeseries will have values between 0 and 1\n",
    "\n",
    "# anomalies\n",
    "p_anomaly = 10E-6\n",
    "max_anomaly_duration = 4*3600 # 4 h\n",
    "\n",
    "# tuning parameters\n",
    "cut = 0.55\n",
    "window = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dti=pd.DatetimeIndex(start=start_date,end=end_date, freq='s')\n",
    "n_timesteps = len(dti)\n",
    "df = pd.DataFrame()\n",
    "for s in range(n_series):\n",
    "    v = np.random.normal(random.random()/2, max_noise_amplitude/random.randint(1, 8), n_timesteps) \n",
    "    df['link '+str(s)] = pd.Series(v)\n",
    "df['Flag']=0\n",
    "df['auc_score']=0.5\n",
    "df.index = dti\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_generate = int(n_timesteps * p_anomaly)\n",
    "for a in range(to_generate):\n",
    "    affects = random.sample(range(n_series), random.randint(1, n_series))\n",
    "    duration = int(max_anomaly_duration * random.random())\n",
    "    start = int(n_timesteps * random.random())\n",
    "    end = min(start+duration, n_timesteps)\n",
    "    print('affected:', affects, df.iloc[start].name, df.iloc[end].name)\n",
    "    for s in affects:\n",
    "        df.iloc[start:end,s] = df.iloc[start:end,s] + random.random() * 0.2\n",
    "    df.iloc[start:end,n_series]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enforce range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df<0] = 0\n",
    "df[df>1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot timeseries. Can take a minute to appear due to plot size and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(figsize=(20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions to check for anomaly and plot roc curves. \n",
    "\n",
    "check_for_anomaly fuction receives both reference and subject dataframes, creates training and testing frames, does classification, tests it, prints auc results, and creates ROC curves when abouve the cut.\n",
    "No outut is expected form this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_anomaly(ref, sub):\n",
    "    \n",
    "    y_ref = pd.Series([0] * ref.shape[0])\n",
    "    X_ref = ref\n",
    "    del X_ref['Flag']\n",
    "    del X_ref['auc_score']\n",
    "    \n",
    "    y_sub = pd.Series([1] * sub.shape[0])\n",
    "    X_sub=sub\n",
    "    del X_sub['Flag']\n",
    "    del X_sub['auc_score']\n",
    "    \n",
    "    # separate Reference and Subject into Train and Test\n",
    "    X_ref_train, X_ref_test, y_ref_train, y_ref_test = train_test_split(X_ref, y_ref, test_size=0.3, random_state=42)\n",
    "    X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_sub, y_sub, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # combine training ref and sub samples\n",
    "    X_train = pd.concat([X_ref_train, X_sub_train])\n",
    "    y_train = pd.concat([y_ref_train, y_sub_train])\n",
    "\n",
    "    # combine testing ref and sub samples\n",
    "    X_test = pd.concat([X_ref_test, X_sub_test])\n",
    "    y_test = pd.concat([y_ref_test, y_sub_test])\n",
    "    \n",
    "    clf = AdaBoostClassifier() #dtc\n",
    "#     clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),algorithm=\"SAMME\",n_estimators=200)\n",
    "    \n",
    "    #train an AdaBoost model to be able to tell the difference between the reference and subject data\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Predict using the combined test data\n",
    "    y_predict = clf.predict(X_test)\n",
    "    \n",
    "    # scores = cross_val_score(clf, X, y)\n",
    "    # print(scores)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_predict) # calculate the false positive rate and true positive rate\n",
    "    auc_score = auc(fpr, tpr) #calculate the AUC score\n",
    "    print (\"auc_score = \", auc_score, \"\\tfeature importances:\", clf.feature_importances_)\n",
    "    \n",
    "    if auc_score > cut: \n",
    "        plot_roc(fpr, tpr, auc_score)\n",
    "        filename='tree_'+sub.index.min().strftime(\"%Y-%m-%d_%H\")\n",
    "        tree.export_graphviz(clf.estimators_[0] , out_file=filename +'_1.dot') \n",
    "        tree.export_graphviz(clf.estimators_[1] , out_file=filename +'_2.dot') \n",
    "        \n",
    "    return auc_score\n",
    "\n",
    "\n",
    "def plot_roc(fpr,tpr, roc_auc):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='r',label='Luck', alpha=.8)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping over time intervals\n",
    "\n",
    "This function actully runs anomaly dection over all the intervals. It takes only few seconds per interval, but plot generation takes 10-20 seconds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find min and max timestamps\n",
    "\n",
    "start = df.index.min()\n",
    "end = df.index.max()\n",
    "\n",
    "#round start \n",
    "start.seconds=0\n",
    "start.minutes=0\n",
    "\n",
    "ref = window * Hour()\n",
    "sub = 1 * Hour()\n",
    "\n",
    "# loop over them\n",
    "ti=start+ref+sub\n",
    "count=0\n",
    "while ti < end + 1 * Minute():\n",
    "    ref_start = ti-ref-sub\n",
    "    ref_end = ti-sub\n",
    "    ref_df = df[(df.index >= ref_start) & (df.index < ref_end)]\n",
    "    sub_df = df[(df.index >= ref_end) & (df.index < ti)]\n",
    "    auc_score = check_for_anomaly(ref_df, sub_df)\n",
    "    df.loc[(df.index>=ref_end) & (df.index<=ti),['auc_score']] = auc_score\n",
    "    print(ti,\"\\trefes:\" , ref_df.shape[0], \"\\tsubjects:\", sub_df.shape[0], '\\tauc:', auc_score)\n",
    "    ti = ti + sub\n",
    "    count=count+1\n",
    "    #if count>2: break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(figsize=(20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make plot of created anomalies, auc values, and shade periods where anomaly is suspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "df.loc[:,'Detected'] = 0\n",
    "df.loc[df.auc_score>0.55,'Detected']=1\n",
    "df.head()\n",
    "ax.plot(df.Flag, 'r')\n",
    "ax.plot(df.auc_score,'g')\n",
    "ax.fill( df.Detected, 'b', alpha=0.3)\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
