{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb6500f-26b2-421f-843c-8888039e8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, exceptions as es_exceptions\n",
    "from elasticsearch.helpers import scan\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77959fba-135a-4beb-99e9-a80317907165",
   "metadata": {},
   "source": [
    "I like to keep Elasticsearch connection configuration in a json file.\n",
    "It should look like this:\n",
    "```json\n",
    "{\n",
    "    \"ES_HOST\": \"atlas-kibana.mwt2.org\",\n",
    "    \"ES_USER\": \"ivukotic\",\n",
    "    \"ES_PASS\": \"xxxxxxxx\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958998d4-c33e-4ebc-9994-9103933c6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as json_data:\n",
    "    config = json.load(json_data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be965f71-e038-41a7-8b8e-608a78e891d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 'xc-gstream' # this is index that contains the data. Can be alias.\n",
    "KB=1024\n",
    "MB=KB*1024\n",
    "GB=MB*1024\n",
    "TB=GB*1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f61419-3f71-4ba7-b76b-089a53f3a98d",
   "metadata": {},
   "source": [
    "Actually connecting to ES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454b887-36be-4671-95a8-7efc0c72ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts=[{'host': config['ES_HOST'], 'scheme':'https', 'port':9200}],\n",
    "    basic_auth=(config['ES_USER'], config['ES_PASS']),\n",
    "    request_timeout=60)\n",
    "\n",
    "if es.ping():\n",
    "    print('connected to ES.')\n",
    "else:\n",
    "    print('no connection to ES.')\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67034bf-0c4d-44c3-8ddf-4669ff20fa99",
   "metadata": {},
   "source": [
    "Just to limit time range..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca7dd2-d19e-4de8-b6f2-4bea9fa5f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_int = '2022-06-01 00:00'\n",
    "stop_int = '2022-07-01 00:00'\n",
    "start_dt = datetime.strptime(start_int, '%Y-%m-%d %H:%M')\n",
    "stop_dt = datetime.strptime(stop_int, '%Y-%m-%d %H:%M')\n",
    "print('start:', start_dt, '\\nstop: ', stop_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8db3d4-c570-4146-aa07-cb1175f44269",
   "metadata": {},
   "source": [
    "An example query. \n",
    "\\_source determins what columns will be returned. Without it all the columns will be returned (possibly slow).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877f017-8d7e-47e2-95a3-67b442672333",
   "metadata": {},
   "outputs": [],
   "source": [
    "query={\n",
    "    \"_source\": ['host', 'access_cnt','lfn', 'size', 'b_bypass', 'b_hit', 'b_miss', 'n_blks', 'n_blks_done'],\n",
    "    \"query\": {\n",
    "        \"range\": {\n",
    "            \"@timestamp\": {\n",
    "                \"gt\": int(start_dt.timestamp()*1000),\n",
    "                \"lte\": int(stop_dt.timestamp()*1000)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4e80a-b4b7-4ee5-9271-b116a9ba2845",
   "metadata": {},
   "source": [
    "Here data is actually read, additionally filtered, and placed in lists that will be turned into a padas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a075a19-6bca-4efe-bbee-ac0d7a373fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'access':[], 'site':[], 'host':[], 'lfn':[], 'scope':[], 'fn':[], \n",
    "'b_hit':[], 'b_miss':[], 'b_bypass':[], 'fsize':[], 'fill':[]}\n",
    "\n",
    "docs_read = 0\n",
    "docs_skipped = 0\n",
    "docs_bad=0\n",
    "\n",
    "scroll = scan(client=es, index=ind, query=query, timeout=\"5m\")\n",
    "\n",
    "for res in scroll:\n",
    "    docs_read += 1\n",
    "    if not docs_read % 50000:\n",
    "        print('docs read', docs_read)\n",
    "        \n",
    "    # print('res',res)\n",
    "    \n",
    "    if not 'host' in res['_source']:\n",
    "        print('bad document:', res)\n",
    "        docs_bad += 1\n",
    "        continue\n",
    "        \n",
    "    site = res['_source']['site']\n",
    "    if site=='UC-AF':\n",
    "        docs_skipped+=1\n",
    "        continue\n",
    "        \n",
    "    lfn=res['_source']['lfn']\n",
    "    t=lfn.split('/')\n",
    "    if len(t[-2])!=2 or len(t[-3])!=2:\n",
    "        print('problematic lfn:', lfn)\n",
    "        docs_bad+=1\n",
    "        continue\n",
    "        \n",
    "    data['site'].append(site)\n",
    "    data['lfn'].append(lfn)\n",
    "    data['host'].append(res['_source']['host'])\n",
    "    data['access'].append(res['_source']['access_cnt'])\n",
    "    if t[-5]=='user':\n",
    "        t[-4]='user.'+t[-4]\n",
    "    data['scope'].append(t[-4])\n",
    "    data['fn'].append(t[-1])\n",
    "    data['b_hit'].append(res['_source']['b_hit'])\n",
    "    data['b_miss'].append(res['_source']['b_miss'])\n",
    "    data['b_bypass'].append(res['_source']['b_bypass'])\n",
    "    data['fsize'].append(res['_source']['size'])\n",
    "    data['fill'].append(res['_source']['n_blks_done']/res['_source']['n_blks'])\n",
    "    \n",
    "    # print('data',data)\n",
    "    # break\n",
    "print('read:', docs_read, 'bad:', docs_bad, 'skipped:', docs_skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac721394-26ef-46fd-bf79-8e644733b3ff",
   "metadata": {},
   "source": [
    "Making and saving pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d217c00-db2d-4f34-88a3-4fd035c696e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame.from_dict(data)\n",
    "df.to_parquet(f'data/xcache_{start_int.split()[0]}.parquet')  \n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
